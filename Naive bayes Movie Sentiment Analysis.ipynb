{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Movie Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes theorem. It assumes there is\n",
    "dependency between every pair of features. The model requires to create a test data and train data on which the classifier is run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posReview = 'C:/Users/roush/Downloads/Python Sentiment Analysis/rt-polaritydata/rt-polaritydata/rt-polarity.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(posReview, 'r') as f:\n",
    "    posReviews = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negReview = 'C:/Users/roush/Downloads/Python Sentiment Analysis/rt-polaritydata/rt-polaritydata/rt-polarity.neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(negReview, 'r') as f:\n",
    "    negReviews = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the corpus into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_train_data = posReviews[:2500]\n",
    "neg_train_data = negReviews[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_test_data = posReviews[2501:]\n",
    "neg_test_data = negReviews[2501:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vocabulary of all the words in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_list= []\n",
    "for line in pos_train_data:\n",
    "    for word in line.split():\n",
    "        pos_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_list = [word for line in neg_train_data for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "for sublist in [pos_list, neg_list]:\n",
    "    for words in sublist:\n",
    "        all_words.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminate duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = (set(all_words))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up training data. Creating a tuple with Review and their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_pos_data = []\n",
    "for review in pos_train_data:\n",
    "    tagged_pos_data.append({'review':review.split(), 'label':'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_neg_data = [{'review':review.split(), 'label':'negative'} for review in neg_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_tagged = []\n",
    "for sublist in [tagged_pos_data, tagged_neg_data]:\n",
    "    for review in sublist:\n",
    "        full_tagged.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', \"century's\", 'new', '\"', 'conan', '\"', 'and', 'that', \"he's\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], 'label': 'positive'}\n",
      "{'review': ['the', 'gorgeously', 'elaborate', 'continuation', 'of', '\"', 'the', 'lord', 'of', 'the', 'rings', '\"', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'cannot', 'adequately', 'describe', 'co-writer/director', 'peter', \"jackson's\", 'expanded', 'vision', 'of', 'j', '.', 'r', '.', 'r', '.', \"tolkien's\", 'middle-earth', '.'], 'label': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "for review in full_tagged[0:2]:\n",
    "    print (review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data =[]\n",
    "for review in full_tagged:\n",
    "    training_data.append((review['review'],review['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'rock',\n",
       "  'is',\n",
       "  'destined',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  '21st',\n",
       "  \"century's\",\n",
       "  'new',\n",
       "  '\"',\n",
       "  'conan',\n",
       "  '\"',\n",
       "  'and',\n",
       "  'that',\n",
       "  \"he's\",\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'splash',\n",
       "  'even',\n",
       "  'greater',\n",
       "  'than',\n",
       "  'arnold',\n",
       "  'schwarzenegger',\n",
       "  ',',\n",
       "  'jean-claud',\n",
       "  'van',\n",
       "  'damme',\n",
       "  'or',\n",
       "  'steven',\n",
       "  'segal',\n",
       "  '.'],\n",
       " 'positive')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction(review):\n",
    "    review_words= set(review)\n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word]=(word in review_words)   # word in review_words returns true or false\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the training data into a list of feature vectors.The first element of training_features tuple is the feature vector and the second element is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features = nltk.classify.apply_features(feature_extraction, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainedNBClassifier = nltk.NaiveBayesClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naiveBayesSentiment(review):\n",
    "    word = review.split()\n",
    "    feature_vector = feature_extraction(word)\n",
    "    return trainedNBClassifier.classify(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayesSentiment('You are the Worst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewSentiments(naiveBayesSentiment):\n",
    "    test_pos = [naiveBayesSentiment(review) for review in pos_test_data]\n",
    "    test_neg = [naiveBayesSentiment(review) for review in neg_test_data]\n",
    "    label = {'positive': 1, 'negative':-1}\n",
    "    numeric_pos = [label[x] for x in test_pos]\n",
    "    numeric_neg = [label[x] for x in test_neg]\n",
    "    return {'positive': numeric_pos, 'negative': numeric_neg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runDiagnostics(reviewResult):\n",
    "    posResult = reviewResult['positive']\n",
    "    negResult = reviewResult['negative']\n",
    "    truePositive = sum(x>0 for x in posResult)\n",
    "    trueNegative = sum(x<0 for x in negResult)\n",
    "    pctTruepos = float(truePositive)/len(posResult)\n",
    "    pctTrueneg = float(trueNegative)/len(negResult)\n",
    "    totalTrue = truePositive + trueNegative\n",
    "    total = len(posResult) + len(negResult)\n",
    "    print ('Accuracy of Positive reviews=' + '%.2f'% (pctTruepos *100) + '%' )\n",
    "    print ('Accuracy of Negative reviews=' + '%.2f'% (pctTrueneg *100) + '%' )\n",
    "    print ('Overall Accuracy=' + '%.2f' % (totalTrue *100/total) + '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Positive reviews=73.39%\n",
      "Accuracy of Negative reviews=77.07%\n",
      "Overall Accuracy=75.23%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(reviewSentiments(naiveBayesSentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
